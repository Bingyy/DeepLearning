{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_cifar10_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingyy/DeepLearning/blob/master/Keras_cifar10_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Amoz0wVMy-y3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Train a simple deep CNN on the CIFAR10 small images dataset.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZwYZdK-uzf8P",
        "colab_type": "code",
        "outputId": "2db52b18-d0b2-43ab-95c7-de4400da4ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], ' train samples')\n",
        "print(x_test.shape[0], ' tese samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000  train samples\n",
            "10000  tese samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWJeKHK-brcv",
        "colab_type": "code",
        "outputId": "bea5aaf3-73ef-4d9c-8db7-4047e3cc3dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "a6PBkYzediag",
        "colab_type": "code",
        "outputId": "e949c33b-0c1c-44e5-8274-5c530bf2ebc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "uU-uhPqfdnH6",
        "colab_type": "code",
        "outputId": "493343ab-5af8-45b9-cd5a-4914767c2735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "# 使用已经训练好的参数来加载模型\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('./saved_models/keras_cifar10_trained_model.h5')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZjLYSya2gdLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def onehot_to_label(res):\n",
        "  label = ''\n",
        "  for i in range(len(res[0])):\n",
        "    if res[0][i] == 1:\n",
        "      label = lst[i]\n",
        "  return label\n",
        "\n",
        "def softmax_to_label(res):\n",
        "  label = ''\n",
        "  index = res[0].argmax()\n",
        "  label = lst[index]\n",
        "  return label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzBxiFEEdw3g",
        "colab_type": "code",
        "outputId": "c04bebbd-7d76-4f29-a704-60ea709cd0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 识别测试集图片\n",
        "test_image = x_test[100].reshape([1,32,32,3])\n",
        "test_image.shape\n",
        "# model.evaluate(x_test, y_test)\n",
        "\n",
        "lst= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "res = model.predict(test_image)\n",
        "\n",
        "# for i in range(len(res[0])):\n",
        "#   if res[0][i] == 1:\n",
        "#     print(lst[i])\n",
        "\n",
        "label = softmax_to_label(res)\n",
        "\n",
        "print(label)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "horse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ie5w9F85dxKp",
        "colab_type": "code",
        "outputId": "7244c24e-86c9-4e6d-8413-972bd8c76e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_test[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "nbTBaPZpdxUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 自己加载raw image进行识别\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "\n",
        "image = Image.open('./images/airplane.jpeg') # 加载图片\n",
        "image = image.resize((32,32))\n",
        "image = img_to_array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tqN_4k5_dxXz",
        "colab_type": "code",
        "outputId": "08bb937e-db27-4773-ae98-2ffc5a190905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "DYyoNgazdxbQ",
        "colab_type": "code",
        "outputId": "1e7b3c6d-1dbf-4b60-c084-78587136dfe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "hFzNCGAi5wpC",
        "colab_type": "code",
        "outputId": "be1cf3f3-8df6-4067-cccd-61b153111664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# 加载进来之后开始预测\n",
        "final = image.reshape([1,32,32,3])\n",
        "res = model.predict(final)\n",
        "label = onehot_to_label(res)\n",
        "print(\"The image is: \", label)\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image is:  airplane\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NOYwn84o5xEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_to_array(path):\n",
        "  image = Image.open(path)\n",
        "  image = image.resize((32,32),Image.NEAREST) # 会将图像整体缩放到指定大小，不是裁剪\n",
        "#   image = image.crop((100,100,132,132))\n",
        "  image = img_to_array(image) # 变成数组\n",
        "  final = image.reshape([1,32,32,3]) # reshape到4维张量\n",
        "  return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WfWYo7bN7dct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv deer.jpeg ./images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QydEVXYo7drB",
        "colab_type": "code",
        "outputId": "bdb61c66-cf93-4468-94e7-6760567965a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "final_image = image_to_array('./deer.jpeg')\n",
        "print(final_image.shape)\n",
        "res = model.predict(final_image)\n",
        "label = softmax_to_label(res)\n",
        "print(label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 32, 32, 3)\n",
            "frog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zj6GjQqL7o8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = Image.open('./deer.jpeg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzMSHOK197_n",
        "colab_type": "code",
        "outputId": "426675fa-fa45-4b6a-d98a-98b27be9d6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "cell_type": "code",
      "source": [
        "image.resize((32,32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAALi0lEQVR4nAXBCXBbhYEA0H/p6+vr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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FBAF989FB00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "mAwtzjIK-Czn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = image.resize((32,32))\n",
        "\n",
        "image = img_to_array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kru2E9MA-M8m",
        "colab_type": "code",
        "outputId": "ea663669-3e81-49bb-ff14-872ce006ba13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "metadata": {
        "id": "aBklTT0R-NTo",
        "colab_type": "code",
        "outputId": "d98b804b-7e84-4fb8-afe6-1799549fb2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "image = image.reshape([1,32,32,3])\n",
        "res = model.predict(image)\n",
        "index = res[0].argmax()\n",
        "\n",
        "print(lst[index])\n",
        "print(softmax_to_label(res))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frog\n",
            "frog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UTeDh1B-AI4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 识别猫\n",
        "cat_image = image_to_array('./cat')\n",
        "res = model.predict(cat_image)\n",
        "label = softmax_to_label(res)\n",
        "\n",
        "print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoKUSHj7AJMz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2w0naZhG0Ujs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
        "\n",
        "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
        "(it's still underfitting at that point, though).\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    \n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        steps_per_epoch = 600,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        validation_steps = 10,\n",
        "                        workers=4)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LLGqr9eo01uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjkB07jQ8Auc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NjDUMGanRz3W",
        "colab_type": "code",
        "outputId": "230e7bca-7301-4524-878c-e38b666152fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9m9RkfkZR1NW",
        "colab_type": "code",
        "outputId": "46439f44-20a5-4e96-8f7f-0a89468e6717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_train[0].shape\n",
        "# model2.predict(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "d0NEiJnVR559",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-PcShy2bD73",
        "colab_type": "code",
        "outputId": "20c1dfa7-9bc3-4805-c152-b6b25579afcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ORU3egcjbK8W",
        "colab_type": "code",
        "outputId": "751e5aa2-df4d-4e06-e759-86f8624807e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 识别测试集图片\n",
        "\n",
        "x_test[0].shape\n",
        "y_test[0].shape\n",
        "# trained_model.predict(x_test[0].reshape([1, 32, 32,3])\n",
        "\n",
        "# scores = trained_model.evaluate(x_test, y_test, verbose=1)\n",
        "# \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "OPGzbeUSb3Yg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}